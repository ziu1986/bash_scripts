#! /bin/bash
# Activate auto completion for environmental variable
shopt -s direxpand

# Setting all neccessary paths
# General settings
export WORKSPACE=$HOME
export DATA=/data
export SOFTWARE=$WORKSPACE/Software
export PY_SCRIPTS=$WORKSPACE/Python
export MODELS=$WORKSPACE/Models

export PYTHONPATH=$PYTHONPATH:$PY_SCRIPTS
export PATH=$PATH:$SOFTWARE/grib_api-1.28.0/bin/bin

# Name
LRZNAME=ra46zot
DKRZNAME=m300917

# ICON docker
set_up () {
    opt1=${1}
    opt2=${2}
    opt_str="Valid options: icon aes, icon les, icon mpi"
    case $opt1 in
        icon)
            export ICON_POOL=$DATA/icon/pool
            case $opt2 in
                aes)
                    echo "Setting ICON-AES"
                    export ICON_ROOT=$MODELS/icon/icon-aes
                    ;;
                les)
                    echo "Setting ICON-LES"
                    export ICON_ROOT=$MODELS/icon/icon-les
                    ;;
                mpi)
                    echo "Setting ICON-MPI"
                    export ICON_ROOT=$MODELS/icon/icon-mpim
                    ;;
                *)
                    echo ${opt_str}
                    ;;
            esac
            update_icon() {
                cd $ICON_ROOT
                git fetch
                git submodule update --recursive
                git pull --recurse-submodules
                cd externals/jsbach
                git switch dev
                git pull
                git merge dev
            }
            update_pool_data() {
               
                pool_data_levante=/pool/data/ICON/grids/public/mpim
                pool_data_jsb_forcing=/pool/data/JSBACH/jsbalone_forcing/R02B04
                grid=0043
                # JSB standalone
                revision=r0004

                # Get icon grid
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/icon_grid_${grid}_R02B04_G.nc $DATA/icon/
                # Get boundary & initial conditions (land)
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/land/${revision}/*1979* $DATA/icon/
                # Greenhous gases
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/independent/greenhouse_gases/greenhouse_historical_plus.nc $DATA/icon/
                # Atmospheric forcing (GSWP3)
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_jsb_forcing}/${grid}/GSWP3-W5E5/data/*_200[0,1]* $DATA/icon/
                
                # For AMIP
                revision=r0001
                # Initial conditions
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/initial_condition/${revision}/ifs2icon_1979010100_R02B04_G.nc $DATA/icon/
                # Atmospheric aerosol
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/aerosol_kinne/${revision}/bc_aeropt_kinne_lw_b16_coa.nc $DATA/icon/
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/aerosol_kinne/${revision}/bc_aeropt_kinne_sw_b14_coa.nc $DATA/icon/
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/aerosol_kinne/${revision}/bc_aeropt_kinne_sw_b14_fin_1850.nc $DATA/icon/
                # Volcanic aerosol
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/independent/CMIP6Forcing/bc_aeropt_cmip6_volc_lw_b16_sw_b14_200[0,1]* $DATA/icon/
                # Ozone
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/ozone/${revision}/*_200[0,1]* $DATA/icon/
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/independent/greenhouse_gases/bc_ozone_cariolle.nc $DATA/icon/
                # SST and SIC
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/${grid}/sst_and_seaice/${revision}/*1979*.nc $DATA/icon/
                # Solar radiation
                rsync -avzRL $DKRZNAME@levante.dkrz.de:${pool_data_levante}/independent/solar_radiation/3.2/swflux_14band_cmip6_1850-2299-v3.2.nc $DATA/icon/
            }
                
            ;;
        blue)
            export BLUE_ROOT=$MODELS/blue
            export BLUE_MODEL=${BLUE_ROOT}/blue_code
            export BLUE_SCRIPTS=${BLUE_ROOT}/blue_RunScripts
            # Activate conda environ
            use_conda
            conda activate blue_env
            ;;
        mpi-esm)
            case ${opt2} in
                hbp)
                    echo "Setting MPI-ESM HBP"
                    export MPIESM_ROOT=${MODELS}/mpi-esm/hbp_mpiesm-landveg
                    ;;
                release)
                    echo "Setting MPI-ESM release"
                    export MPIESM_ROOT=${MODELS}/mpi-esm/mpiesm-1.2.01p5
                    ;;
                *)
                    echo "Setting MPI-ESM landveg"
                    export MPIESM_ROOT=${MODELS}/mpi-esm/mpiesm-landveg
                    ;;
            esac
            ;;
        *)
            echo ${opt_str}
            ;;
    esac
}

# Include Panoply
alias panoply=${SOFTWARE}/PanoplyJ/panoply.sh

# Mounting of network resources
src_data() {
    target=${1}
    mode=${2}
    case $target in
        saga)
            echo "Mounting saga/work"
            sshfs sfalk@saga.sigma2.no:/cluster/work/users/sfalk ${DATA}/saga
            ;;
        input_data)
            echo "Mounting saga/input_data"
            sshfs sfalk@saga.sigma2.no:/cluster/projects/nn9188k/OsloCTM3 ${DATA}/CTM3_input_data
            ;;
        BrXplo)
            echo "Mounting BrXplo on pfs"
            sshfs hy0485@uc1.scc.kit.edu:/pfs/imk/imk-asf/common/results/EMAC/BrXplo ${DATA}/BrXplo_data
            ;;
        CTM3_Oivind)
            echo "Mounting /div/pdo/cixpag/oivinho/CTM3_output/"
            sshfs sfalk@pdo.uio.no:/div/pdo/cixpag/oivinho/CTM3_output/ ${DATA}/CTM3_Oivind_data
            ;;
        astra)
            echo "Mounting ASTRA"
            sshfs sfalk@login.uio.no:/net/astra/astra-01/sfalk/ ${DATA}/astra
            ;;
        nird)
            echo "Mounting /tos-project1/NS2806K/sfalk/"
            sshfs sfalk@login.nird.sigma2.no:/tos-project1/NS2806K/sfalk/ ${DATA}/nird
            ;;
        uio_home)
            echo "Mounting /uio/kant/geo-metos-u4/sfalk/"
            sshfs sfalk@login.uio.no:/uio/kant/geo-metos-u1/sfalk/privat/Documents/ /kant
            ;;
        nas)
            echo "Mounting nas"
            sudo mount -t davfs -o uid=sfalk,gid=sfalk https://webdisk.ads.mwn.de/hcwebdav $DATA/nas
            ;;
        *)
            echo "No valid mount point!"
            echo "Options: saga; astra; nird; uio_home; nas"
    esac
    #
}

unsrc_data() {
    tgt=${1}
    fusermount -uz $tgt

}

use_conda() {
    # >>> conda initialize >>>
    # !! Contents within this block are managed by 'conda init' !!
    __conda_setup="$('/home/sfalk/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
    if [ $? -eq 0 ]; then
        eval "$__conda_setup"
    else
        if [ -f "/home/sfalk/anaconda3/etc/profile.d/conda.sh" ]; then
            . "/home/sfalk/anaconda3/etc/profile.d/conda.sh"
        else
            export PATH="/home/sfalk/anaconda3/bin:$PATH"
        fi
    fi
    unset __conda_setup
    # <<< conda initialize <<<
}

# SSH-AGENT
SSH_ENV="$HOME/.ssh/agent-environment"    

trap '
         test -n "$SSH_AGENT_PID"  && eval `ssh-agent -k`
 ' 0                                          

function start_agent {                                                      
    echo -n "Initialising new SSH agent ... "                                
    /usr/bin/ssh-agent | sed 's/^echo/#echo/' > "${SSH_ENV}"            
    echo succeeded                                                          
    chmod 600 "${SSH_ENV}"                                                  
    source "${SSH_ENV}" > /dev/null                                         
    /usr/bin/ssh-add;                                                   
}

if [[ -f "${SSH_ENV}" ]]                                                    
then                                                                        
    source "${SSH_ENV}" > /dev/null                                         
    ps -ef | grep ${SSH_AGENT_PID} | grep ssh-agent$ > /dev/null || {       
        start_agent;                                                        
    }                                                                       
else                                                                        
    start_agent;                                                            
fi

# Alias
alias ssh_centos='ssh -X -i ~/.ssh/iaas-cloud_ceres.key.pub centos@158.39.75.138'


echo "Setting work environment..."
